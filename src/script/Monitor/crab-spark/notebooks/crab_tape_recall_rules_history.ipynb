{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9af689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkContext, StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    current_user,\n",
    "    col, collect_list, concat_ws, greatest, lit, lower, when,\n",
    "    avg as _avg,\n",
    "    count as _count,\n",
    "    hex as _hex,\n",
    "    max as _max,\n",
    "    min as _min,\n",
    "    round as _round,\n",
    "    sum as _sum,\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    LongType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    IntegerType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22946659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/01 23:31:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://swan-gpu-t4-5x-jfkrw7kar3a2-node-17:31614\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark_shell_swan</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff74ffe7820>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('tape-recall-history')\\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "014b13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31c19eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments\n",
    "# secret path, also check if file exists\n",
    "secretpath = os.environ.get('OPENSEARCH_SECRET_PATH', f'{os.getcwd()}/../workdir/secret_opensearch.txt')\n",
    "with open(secretpath, 'r') as r:\n",
    "    pass\n",
    "# if PROD, index prefix will be `crab-*`, otherwise `crab-test-*`\n",
    "PROD = os.environ.get('PROD', 'false').lower() in ('true', '1', 't')\n",
    "# FROM_DATE, in strptime(\"%Y-%m-%d\")\n",
    "START = os.environ.get('START_DATE', None) \n",
    "END = os.environ.get('END_DATE', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e843eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to import osearch from current directory, fallback to $PWD/../workdir if not found\n",
    "try:\n",
    "    import osearch\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    sys.path.insert(0, f'{os.getcwd()}/../workdir')\n",
    "    import osearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c644790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for run inside notebook\n",
    "START_DATE = \"2000-01-01\"\n",
    "END_DATE = \"2024-10-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "029d9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# const variable\n",
    "index_name = 'crab-test-tape-recall-history' # always put test index prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b17ed53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cronjob, replace constant with value from env\n",
    "if START and END:\n",
    "    START_DATE = START\n",
    "    END_DATE = END\n",
    "# use prod index pattern if this execution is for production\n",
    "if PROD:\n",
    "    index_name = f'crab-{\"-\".join(index_name.split(\"-\")[2:])}'\n",
    "# datetime object\n",
    "start_datetime = datetime.strptime(START_DATE, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "end_datetime = datetime.strptime(END_DATE, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "if end_datetime < start_datetime:\n",
    "    raise Exception(f\"end date ({END_DATE}) is less than start date ({START_DATE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9404c437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01\n",
      "2000-01-01 00:00:00+00:00\n",
      "2024-10-01\n",
      "2024-10-01 00:00:00+00:00\n",
      "crab-test-tape-recall-history\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "print(START_DATE, \n",
    "      start_datetime, \n",
    "      END_DATE, \n",
    "      end_datetime, \n",
    "      index_name,\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e85c2f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "RUCIO : Rules History\n",
      "===============================================\n",
      "File Directory:\n",
      "/project/awg/cms/rucio/2024-10-01/rules_history/\n",
      "Work Directory:\n",
      "/eos/home-i00/t/tseethon/SWAN_projects/CRABServer/src/script/Monitor/crab-spark/notebooks\n",
      "===============================================\n",
      "===============================================\n",
      "===============================================\n",
      "CRAB Table\n",
      "===============================================\n",
      "File Directory:\n",
      "/project/awg/cms/crab/tasks/2024-10-01/\n",
      "Work Directory:\n",
      "/eos/home-i00/t/tseethon/SWAN_projects/CRABServer/src/script/Monitor/crab-spark/notebooks\n",
      "===============================================\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "# Import data into spark\n",
    "\n",
    "HDFS_RUCIO_RULES_HISTORY = f'/project/awg/cms/rucio/{END_DATE}/rules_history/'\n",
    "\n",
    "print(\"===============================================\"\n",
    "      , \"RUCIO : Rules History\"\n",
    "      , \"===============================================\"\n",
    "      , \"File Directory:\", HDFS_RUCIO_RULES_HISTORY\n",
    "      , \"Work Directory:\", os.getcwd()\n",
    "      , \"===============================================\"\n",
    "      , \"===============================================\", sep='\\n')\n",
    "\n",
    "# we only interest in the rules where state does not change anymore.\n",
    "# which means, only the rules that already expired.\n",
    "rucio_rules_history = (\n",
    "    spark.read.format('avro').load(HDFS_RUCIO_RULES_HISTORY).withColumn('ID', lower(_hex(col('ID'))))\n",
    "         .select(\"ID\", \"ACCOUNT\", \"NAME\", \"STATE\", \"EXPIRES_AT\", \"UPDATED_AT\", \"CREATED_AT\").filter(f\"\"\"ACTIVITY = 'Analysis TapeRecall'\"\"\").cache()\n",
    "         .filter(f\"\"\"\\\n",
    "                  1=1\n",
    "                  AND EXPIRES_AT >= {int(start_datetime.timestamp()) * 1000}\n",
    "                  AND EXPIRES_AT < {int(end_datetime.timestamp()) * 1000}\n",
    "                  \"\"\")\n",
    "         .cache()\n",
    ")\n",
    "rucio_rules_history.createOrReplaceTempView(\"rules_history\")\n",
    "\n",
    "HDFS_CRAB_part = f'/project/awg/cms/crab/tasks/{END_DATE}/'\n",
    "print(\"===============================================\"\n",
    "      , \"CRAB Table\"\n",
    "      , \"===============================================\"\n",
    "      , \"File Directory:\", HDFS_CRAB_part\n",
    "      , \"Work Directory:\", os.getcwd()\n",
    "      , \"===============================================\"\n",
    "      , \"===============================================\", sep='\\n')\n",
    "\n",
    "# do not filter taskdb by create time (TM_START_TIME) because it is possible that rules are created 6 months ago\n",
    "tasks_df = (\n",
    "    spark.read.format('avro').load(HDFS_CRAB_part)\n",
    "         .select(\"TM_TASKNAME\",\"TM_START_TIME\",\"TM_TASK_STATUS\",  'TM_TASKNAME', 'TM_START_TIME', 'TM_TASK_STATUS' , 'TM_DDM_REQID')\n",
    "         .cache()\n",
    ")\n",
    "tasks_df.createOrReplaceTempView(\"tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e271b1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+-----+----+-------------+-------------+-------------+--------------------+-------------+--------------+-------------+-------------------+\n",
      "|                  ID| ACCOUNT|                NAME|STATE|DAYS|   EXPIRES_AT|   UPDATED_AT|   CREATED_AT|         TM_TASKNAME|TM_START_TIME|TM_TASK_STATUS|    timestamp|               type|\n",
      "+--------------------+--------+--------------------+-----+----+-------------+-------------+-------------+--------------------+-------------+--------------+-------------+-------------------+\n",
      "|0006907403fe4e948...|   tihsu|/DoublePhoton_Fla...|    O|   6|1726479827000|1726134227000|1725642766000|240906_171202:tih...|1725635522631|     SUBMITTED|1725642766000|tape_recall_history|\n",
      "|002657a392fe46799...|  joshin|/Muon1/Run2024C-P...|    O|   6|1726479828000|1726436909000|1725985568000|240910_162509:jos...|1725978309883|        KILLED|1725985568000|tape_recall_history|\n",
      "|007fa987e8b94ae98...|   tihsu|/SinglePhoton_Pt-...|    O|   4|1726250781000|1725905181000|1725642798000|240906_171249:tih...|1725635570164|     SUBMITTED|1725642798000|tape_recall_history|\n",
      "|0201b5b36a9546a79...|   daebi|/ZeroBias/Run2024...|    U|  22|1726403067000|1725718610000|1724502267000|240824_122338:dae...|1724495018286|        FAILED|1724502267000|tape_recall_history|\n",
      "|028a5ca0f941415e8...|jmejiagu|/HIPhysicsRawPrim...|    R|   2|1724261922000|1724258322000|1724133700000|240820_060111:jme...|1724126471899|        KILLED|1724133700000|tape_recall_history|\n",
      "|058c85a3008d46f1b...|lrouseli|/WJetsToLNu_HT-12...|    R|   1|1725041410000|1725037810000|1725007655000|240830_084658:lro...|1725000418805|        KILLED|1725007655000|tape_recall_history|\n",
      "|059bd3a99b3b41b9a...|amilieva|/Muon0/Run2023C-P...|    O|   1|1727491472000|1727145872000|1727090454000|240923_113102:ami...|1727083862527|     SUBMITTED|1727090454000|tape_recall_history|\n",
      "|05c7603ed8594a7ab...|dbruschi|/ZeroBias/Run2024...|    O|  13|1726171261000|1725825661000|1724774240000|240827_155632:dbr...|1724766992199|     SUBMITTED|1724774240000|tape_recall_history|\n",
      "|05eb729cbaf641189...|   pchou|/PPRefZeroBias14/...|    O|   1|1727325433000|1726979833000|1726969009000|240922_013605:pch...|1726961766092|     SUBMITTED|1726969009000|tape_recall_history|\n",
      "|0639080709c2405e8...|   pchou|/PPRefZeroBias13/...|    O|   1|1727325433000|1726979833000|1726969008000|240922_013534:pch...|1726961735010|     SUBMITTED|1726969008000|tape_recall_history|\n",
      "|0643e46f4ba040aca...|   jiyoo|/QCD_Pt_120to170_...|    O|   9|1726985717000|1726640117000|1725932369000|240910_013747:jiy...|1725925067495|     SUBMITTED|1725932369000|tape_recall_history|\n",
      "|07bef5038e7c4f298...|sibashir|/TTTo2L2Nu_mtop17...|    O|   3|1724990602000|1724658649000|1724481343000|240824_063521:sib...|1724474121879|     SUBMITTED|1724481343000|tape_recall_history|\n",
      "|087a2a19d88b4955b...|     nbi|/SUSYGluGluToBBHT...|    O|   1|1727007393000|1726661793000|1726642697000|240918_065710:nbi...|1726635430616|     SUBMITTED|1726642697000|tape_recall_history|\n",
      "|0909160a492a401f8...|  aguven|/ST_tW_antitop_5f...|    O|  21|1726134758000|1726003402000|1724233958000|240821_095153:agu...|1724226713415|        FAILED|1724233958000|tape_recall_history|\n",
      "|098c45a7f2f84c0db...| matheus|/SingleElectron/R...|    O|   1|1727657619000|1727312019000|1727280421000|240925_160615:mat...|1727273175508|     SUBMITTED|1727280421000|tape_recall_history|\n",
      "|0b553928e0a64de6a...|   daebi|/ZeroBias/Run2024...|    U|  22|1726403191000|1725721730000|1724502391000|240824_122533:dae...|1724495133776|        FAILED|1724502391000|tape_recall_history|\n",
      "|0cc2ac0e039d45ff8...|  aguven|/QCD_HT500to700_T...|    O|   1|1724643615000|1724298015000|1724257450000|240821_162323:agu...|1724250204173|     SUBMITTED|1724257450000|tape_recall_history|\n",
      "|0ce1139b4bfe43dab...|   friti|/TTToSemiLeptonic...|    O|   3|1726516026000|1726170426000|1725957617000|240910_083914:fri...|1725950354489|     SUBMITTED|1725957617000|tape_recall_history|\n",
      "|0dd33f98a8ec41cea...|lrouseli|/WJetsToLNu_HT-12...|    O|  12|1726359128000|1726013528000|1725041639000|240830_181335:lro...|1725034415055|     SUBMITTED|1725041639000|tape_recall_history|\n",
      "|0de640323fa74560b...|rhaberle|/HSCPtauPrimeChar...|    O|   1|1723883062000|1723537462000|1723533758000|240813_072201:rha...|1723526521080|     SUBMITTED|1723533758000|tape_recall_history|\n",
      "+--------------------+--------+--------------------+-----+----+-------------+-------------+-------------+--------------------+-------------+--------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query data in daily\n",
    "\n",
    "query = f\"\"\"\\\n",
    "WITH rn_t AS (\n",
    "SELECT ID, ACCOUNT, NAME, STATE, EXPIRES_AT, UPDATED_AT, CREATED_AT,\n",
    "       row_number() over(partition by ID order by UPDATED_AT desc) as row_num\n",
    "FROM rules_history\n",
    "),\n",
    "latestupdate_t AS (\n",
    "SELECT * FROM rn_t \n",
    "WHERE row_num = 1\n",
    "),\n",
    "calc_days_t AS (\n",
    "SELECT ID, ACCOUNT, NAME, STATE, EXPIRES_AT, UPDATED_AT, CREATED_AT,\n",
    "       CASE \n",
    "           WHEN STATE = 'O' THEN ceil((UPDATED_AT-CREATED_AT)/86400000)  \n",
    "           WHEN STATE != 'O' AND EXPIRES_AT < {int(end_datetime.timestamp()) * 1000} THEN ceil((EXPIRES_AT-CREATED_AT)/86400000)\n",
    "           ELSE 0\n",
    "       END AS DAYS\n",
    "FROM latestupdate_t\n",
    "),\n",
    "join_t AS (\n",
    "SELECT * FROM calc_days_t\n",
    "LEFT JOIN tasks ON calc_days_t.ID = tasks.TM_DDM_REQID\n",
    "),\n",
    "window_t AS (\n",
    "SELECT ID, ACCOUNT, NAME, STATE, DAYS, EXPIRES_AT, UPDATED_AT, CREATED_AT, TM_TASKNAME, TM_START_TIME, TM_TASK_STATUS, \n",
    "       row_number() OVER (PARTITION BY join_t.ID ORDER BY join_t.TM_START_TIME DESC) AS row_num\n",
    "FROM join_t \n",
    "),\n",
    "uniqueid_t AS (\n",
    "SELECT *\n",
    "FROM window_t\n",
    "WHERE row_num =1\n",
    "), \n",
    "finalize_t AS (\n",
    "SELECT ID, ACCOUNT, NAME, STATE, DAYS, EXPIRES_AT, UPDATED_AT, CREATED_AT, TM_TASKNAME, IFNULL(TM_START_TIME, 0) as TM_START_TIME, TM_TASK_STATUS, \n",
    "       CREATED_AT AS timestamp,\n",
    "       'tape_recall_history' AS type\n",
    "FROM uniqueid_t\n",
    ")\n",
    "SELECT * \n",
    "FROM finalize_t\n",
    "\"\"\"\n",
    "\n",
    "tmpdf = spark.sql(query)\n",
    "tmpdf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58b3e05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c33dfce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = tmpdf.toPandas().to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eee4a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "        \"settings\": {\"index\": {\"number_of_shards\": \"1\", \"number_of_replicas\": \"1\"}},\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"ID\": {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                \"ACCOUNT\": {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                \"NAME\": {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                \"STATE\": {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                \"DAYS\": {\"type\": \"long\"},\n",
    "                \"EXPIRES_AT\": {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                \"UPDATED_AT\": {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                \"CREATED_AT\": {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                \"TM_TASKNAME\": {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                \"TM_START_TIME\": {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "                \"TM_TASK_STATUS\": {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                \"type\": {\"ignore_above\": 2048, \"type\": \"keyword\"},\n",
    "                \"timestamp\": {\"format\": \"epoch_millis\", \"type\": \"date\"},\n",
    "            }\n",
    "\n",
    "        }\n",
    "\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ec824ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727654400\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(osearch)\n",
    "timestamp_str = int((end_datetime-timedelta(days=1)).timestamp()) # to convert to 'crab-test-taskdb-2024-09' in osearch lib, unit is seconds\n",
    "print(timestamp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "osearch.send_os(docs, index_name, schema, secretpath, timestamp_str)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": [
    {
     "name": "spark.jars.packages",
     "value": "org.apache.spark:spark-avro_2.12:3.5.0"
    },
    {
     "name": "spark.executor.instances",
     "value": "20"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
